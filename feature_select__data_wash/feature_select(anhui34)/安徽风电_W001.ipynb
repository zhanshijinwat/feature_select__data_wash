{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import json\n",
    "# from tqdm import tqdm,trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 根据水平方向风速和垂直方向风速计算出合成的总风速以及风向角度\n",
    "def gather_uvwind(abs_vwind,abs_uwind,v_pos_idx,u_pos_idx):\n",
    "    big_wind_counter = 0\n",
    "    all_counter = 0\n",
    "    tan_wind = abs_vwind/abs_uwind\n",
    "    # 矫正到第一象限的角度\n",
    "    angle_wind = np.arctan(tan_wind)\n",
    "    #合成风速\n",
    "    wind_speed = np.cos(angle_wind)*abs_uwind+np.sin(angle_wind)*abs_vwind\n",
    "    big_wind_counter += np.sum(wind_speed>15)\n",
    "    all_counter += len(wind_speed)\n",
    "    # 将矫正到第一象限的角度修正到实际的角度\n",
    "    angle_wind = (angle_wind/np.pi)*180\n",
    "    for i in range(len(angle_wind)):\n",
    "        # 第一象限\n",
    "        if v_pos_idx[i]==True and u_pos_idx[i]==True:\n",
    "            pass\n",
    "        #第二象限\n",
    "        elif v_pos_idx[i]==True and u_pos_idx[i]==False:\n",
    "            angle_wind[i] = 180-angle_wind[i]\n",
    "        #第三象限\n",
    "        elif v_pos_idx[i]==False and u_pos_idx[i]==False:\n",
    "            angle_wind[i] = 180+angle_wind[i]\n",
    "        # 第四象限\n",
    "        elif v_pos_idx[i]==False and u_pos_idx[i]==True:\n",
    "            angle_wind[i] = 360-angle_wind[i]\n",
    "        else:\n",
    "            raise NameError\n",
    "    print(\"风速范围:\",np.min(wind_speed),\"  \",np.max(wind_speed))\n",
    "    print(\"风向范围:\",np.min(angle_wind),\"  \",np.max(angle_wind))\n",
    "    return wind_speed,angle_wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J001_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J002_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J003_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J004_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J005_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J006_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J007_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J008_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J009_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J010_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J011_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J012_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J013_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J014_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J015_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J016_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J017_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J018_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J019_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J020_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J021_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J022_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J023_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J024_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J025_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J026_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J027_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J028_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J029_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J030_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J031_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J032_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J033_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J034_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J035_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J036_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J037_W001_R_20180103-20201107.csv', '.\\\\20210228_raw_anhui_data\\\\anhui_wind_W001\\\\EEE09001J038_W001_R_20180103-20201107.csv']\n",
      "EEE09001P001\n",
      "EEE09001P002\n",
      "EEE09001P003\n",
      "EEE09001P004\n",
      "EEE09001P005\n",
      "EEE09001P006\n",
      "EEE09001P007\n",
      "EEE09001P008\n",
      "EEE09001P009\n",
      "EEE09001P010\n",
      "EEE09001P011\n",
      "EEE09001P012\n",
      "EEE09001P013\n",
      "EEE09001P014\n",
      "EEE09001P015\n",
      "EEE09001P016\n",
      "EEE09001P017\n",
      "EEE09001P018\n",
      "EEE09001P019\n",
      "EEE09001P020\n",
      "EEE09001P021\n",
      "EEE09001P022\n",
      "EEE09001P023\n",
      "EEE09001P024\n",
      "EEE09001P025\n",
      "EEE09001P026\n",
      "EEE09001P027\n",
      "EEE09001P028\n",
      "EEE09001P029\n",
      "EEE09001P030\n",
      "EEE09001P031\n",
      "EEE09001P032\n",
      "EEE09001P033\n",
      "EEE09001P034\n",
      "EEE09001P035\n",
      "EEE09001P036\n",
      "EEE09001P037\n",
      "EEE09001P038\n",
      "{'RHU_112': {'min': -0.39261999999999997, 'max': 108.60892}, 'UWIND_001': {'min': -11.37756, 'max': 11.90817}, 'AHU_120': {'min': -0.00118, 'max': 5.17702}, 'TMP_112': {'min': -19.898889999999966, 'max': 16.911279999999977}, 'TMP_106': {'min': -14.426459999999963, 'max': 25.729390000000024}, 'TMP_103': {'min': -11.714760000000012, 'max': 31.965720000000033}}\n"
     ]
    }
   ],
   "source": [
    "# 直接生成离线平台需要的格式\n",
    "weather = \"W001\"\n",
    "version = \"v7\"\n",
    "result_dir = \"./processed_data/{}_processed{}\".format(weather,version)\n",
    "if not os.path.exists(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "weather_set = \"anhui_wind_{}\".format(weather)\n",
    "result_format = \"SJQXT0_xz{}all\".format(weather)\n",
    "file_list = glob.glob(\".\\\\20210228_raw_anhui_data\\\\\"+weather_set+\"\\\\*.csv\")\n",
    "print(file_list)\n",
    "# 根据特征筛选.ipynb脚本结果，手动将usecols改成筛选出来的特征\n",
    "usecols = [\"DateTime\",\"RHU_112\",\"UWIND_001\",\"AHU_120\",\"TMP_112\",\"TMP_106\",\"TMP_103\"]\n",
    "min_max_dict = {}\n",
    "for file in file_list:\n",
    "    csv_data = pd.read_csv(file,index_col=None,header=0,usecols=usecols)\n",
    "    # 温度转化，将开式温度转换为摄氏温度\n",
    "    csv_data[\"TMP_112\"] = csv_data[\"TMP_112\"]-273.15\n",
    "    csv_data[\"TMP_106\"] = csv_data[\"TMP_106\"]-273.15\n",
    "    csv_data[\"TMP_103\"] = csv_data[\"TMP_103\"]-273.15\n",
    "\n",
    "    #时间格式转换\n",
    "    result_csv = pd.DataFrame()\n",
    "    result_csv[\"datatime\"] = csv_data[\"DateTime\"].values\n",
    "    result_csv[\"datatime\"] = pd.to_datetime(result_csv[\"datatime\"],format='%Y-%m-%d %H:%M:%S')\n",
    "    result_csv[\"datatime\"] = result_csv[\"datatime\"].apply(lambda x:x.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "   \n",
    "    for i in usecols:\n",
    "        if i==\"DateTime\":\n",
    "            continue\n",
    "        result_csv[i] = csv_data[i].values\n",
    "    \n",
    "    for col in result_csv.columns:\n",
    "        if col != \"datatime\" and col not in min_max_dict:\n",
    "            min_max_dict[col] = {\"min\":float(\"inf\"),\"max\":-99}\n",
    "    # 记录各个特征的最大最小值，用于后续程序的min-max归一化        \n",
    "    for col in result_csv.columns:\n",
    "        if col !=\"datatime\":\n",
    "            min_max_dict[col][\"min\"] = min(min_max_dict[col][\"min\"],np.min(result_csv[col]))\n",
    "            min_max_dict[col][\"max\"] = max(min_max_dict[col][\"max\"],np.max(result_csv[col]))\n",
    "    farm_J_name = file.split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    farm_P_name = farm_J_name[:8]+\"P\"+farm_J_name[9:]\n",
    "    print(farm_P_name)\n",
    "    result_csv.to_csv(\"./{}/{}{}.csv\".format(result_dir,farm_P_name,result_format),index=None)\n",
    "print(min_max_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 生成筛选后特征的json文件，含有对应特征的最大最小值\n",
    "# 保证顺序\n",
    "save_dir = \"./json/{}/{}.json\".format(version,weather)\n",
    "result_csv_columns = list(result_csv.columns)\n",
    "result_csv_columns.remove(\"datatime\")\n",
    "assert(result_csv_columns==list(min_max_dict.keys()))\n",
    "result_dict = {}\n",
    "# result_dict[\"real_day\"] = [\"loop\", 366, -1]\n",
    "# result_dict[\"real_hour\"] = [\"loop\", 96, -1]\n",
    "for col in result_csv_columns:\n",
    "    max_num = min_max_dict[col][\"max\"]\n",
    "    min_num = min_max_dict[col][\"min\"]\n",
    "    result_dict[\"xz{}all_{}\".format(weather,col)] = [\"float\",round(max_num,2),round(min_num,2)]\n",
    "\n",
    "b = json.dumps(result_dict)\n",
    "f2 = open(save_dir, 'w')\n",
    "f2.write(b)\n",
    "f2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
